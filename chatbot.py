from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from config import OPENAI_API_KEY


def get_response(user_input, history):
    """ì±—ë´‡ ì‘ë‹µ ìƒì„± í•¨ìˆ˜"""
    prompt_template = """ğŸ“– ì„±ê²½ ì§€ì‹ì„ ì•Œë ¤ì£¼ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. 
    ì§ˆë¬¸ìì˜ ë¬¸ì˜ì— ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì„±ê²½ ì§€ì‹ì—ì„œ ë²—ì–´ë‚˜ëŠ” ë‚´ìš©ì€ ë‹µë³€í•´ì£¼ì§€ ë§ˆì„¸ìš”.

    {history}
    user: {user_input}
    """

    # LangChain Prompt ì„¤ì •
    prompt = PromptTemplate.from_template(prompt_template)

    # LangChain LLM ì„¤ì •
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0, openai_api_key=OPENAI_API_KEY)
    parser = StrOutputParser()
    chain = (prompt | llm | parser)

    # ëŒ€í™” ì´ë ¥ ì •ë¦¬
    history_text = '\n'.join([':'.join(entry.values()) for entry in history])

    # ì‘ë‹µ ìƒì„±
    response = chain.invoke({"user_input": user_input, "history": history_text})
    return response