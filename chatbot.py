from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from config import OPENAI_API_KEY

# ğŸ”¹ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
TEMPLATE = """ 
ë‹¹ì‹ ì€ êµíšŒì—ì„œ ê¹Šì€ ê´€ê³„ë¥¼ ë§ºì€ ì ˆì¹œí•œ ì¹œêµ¬ì´ë©°, ì„±ê²½í’€ì´ì— ëŠ¥í•œ ì—­í• ì„ ê°€ì¡ŒìŠµë‹ˆë‹¤. 
ì§ˆë¬¸ìì˜ ì„±ê²½ ì§ˆë¬¸ì— ëŒ€í•´ ì˜ˆìˆ˜ë‹˜ì˜ ê°€ë¥´ì¹¨ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.  
ì§ˆë¬¸ìì˜ ì‹ ì•™ì ì¸ ê³ ë¯¼ê³¼ ê¸°ë„ ì œëª©ì„ ê²½ì²­í•˜ê³ ,  
ì„±ê²½ êµ¬ì ˆì„ ì œì‹œí•˜ë©° ë¬µìƒê³¼ ê¸°ë„ë¥¼ ë„ìš¸ ìˆ˜ ìˆë„ë¡ ì¡°ì–¸í•´ ì£¼ì„¸ìš”.  
ëª…ë ¹ì¡°ê°€ ì•„ë‹Œ ì¹œê·¼í•˜ê²Œ ë™ê°‘ì¹œêµ¬ì—ê²Œ ë§í•˜ëŠ” ë§íˆ¬ë¡œ, ì¹œì ˆí•˜ê³  ê³µê°í•˜ë©° ë‹µë³€í•´ ì£¼ì„¸ìš”.
ë‹¨, ë…¼ë€ì´ ë  ìˆ˜ ìˆëŠ” ì£¼ì œëŠ” ê°ê´€ì ìœ¼ë¡œ ì„¤ëª…í•˜ê³ , ê°œì¸ì ì¸ ì‹ ë…ì„ ê°•ìš”í•˜ì§€ ë§ˆì„¸ìš”.  

{history}
user: {user_input}
"""


def get_response_stream(user_input, history, api_key):
    """ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì±—ë´‡ ì‘ë‹µ ìƒì„±"""
    # ğŸ”¹ í”„ë¡¬í”„íŠ¸ & LLM ì„¤ì •
    prompt = PromptTemplate.from_template(TEMPLATE)
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0, openai_api_key=api_key)
    parser = StrOutputParser()

    # ğŸ”¹ ì²´ì¸ ìƒì„± (í”„ë¡¬í”„íŠ¸ â†’ LLM â†’ íŒŒì„œ)
    chain = (prompt | llm | parser)

    # ğŸ”¹ ëŒ€í™” ì´ë ¥ ê°€ê³µ
    history_text = '\n'.join([':'.join(entry.values()) for entry in history])

    # ğŸ”¹ OpenAI API ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
    return chain.stream({"user_input": user_input, "history": history_text})
